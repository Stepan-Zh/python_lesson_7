{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый пункт, который предлагается выполнить в рамках домашнего задания, имеет объявленную \"цену\" в баллах. Максимально возможная сумма – 10 баллов, а с учётом бонусных пунктов – 12 баллов. Выполнять все пункты не обязательно, можно сделать только часть. В большинстве пунктов ожидается, что вы напишете работающий код на Python; иногда надо будет писать комментарии в свободной форме – например, сравнивать несколько подходов к решению одной задачи. Там, где оставлены пустые клетки под ваши ответы, вы можете по своему усмотрению добавлять ещё клетки.\n",
    "\n",
    "* * *\n",
    "\n",
    "Эта лабораторная работа посвящена кластеризации. Мы будем работать с рукописными изображениями цифр, научимся их кластеризовать двумя разными методами (иерархическая кластеризация и алгоритм $K$-means), оценивать качество разбиения и выбирать оптимальное число кластеров, а также визуализировать промежуточные результаты.\n",
    "\n",
    "# 1. Получение данных\n",
    "\n",
    "Данные, с которыми мы будем работать, доступны в библиотеке scikit-learn (модуль называется `sklearn`) в подмодуле `datasets` через функцию, которая называется `load_digits`. Всего имеется 1797 наблюдений, каждое из них представляет чёрно-белую картинку 8 $\\times$ 8 пикселей. Эти картинки – распознанные рукописные цифры от 0 до 9. Образцов написания каждой цифры дано приблизительно поровну, около 180.\n",
    "\n",
    "Для удобства использования данных каждая картинка \"развёрнута\" в строку, так что NumPy-массив, в котором хранятся данные, имеет размерность 2 и величину 1797 $\\times$ 64 (а не, например, размерность 3 и величину 1797 $\\times$ 8 $\\times$ 8). Интенсивность цвета в каждом пикселе кодируется целым числом от 0 до 16.\n",
    "\n",
    "Кроме наблюдений (картинок), известны соответствующие им значения целевой переменной: какую цифру на самом деле изображает каждая картинка. Мы могли бы сразу сформулировать задачу обучения с учителем и предсказывать цифры по картинкам, но для целей этой лабораторной работы мы будем действовать по-другому: сделаем вид, что нам не известны истинные метки классов (т. е. цифры) и даже количество классов, и попробуем сгруппировать данные таким образом, чтобы качество кластеризации оказалось наилучшим, а затем посмотрим, насколько точно полученные кластеры совпадают с группами изображений одинаковых цифр.\n",
    "\n",
    "**(0.5 балла)** Загрузите данные. Добейтесь, чтобы в переменной `X` оказался массив наблюдений, содержащий 1797 $\\times$ 64 числа, а в переменной `y` – массив истинных меток классов, содержащий 1797 чисел.\n",
    "\n",
    "*Указания:*\n",
    "- Как загрузить данные, объяснено в справке к функции `load_digits`.\n",
    "- Размер массива хранится в атрибуте `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64) <class 'numpy.ndarray'> \n",
      "\n",
      "(1797,) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "X, y = datasets.load_digits(n_class=10, return_X_y=True)\n",
    "print(X.shape, type(X), \"\\n\")\n",
    "print(y.shape, type(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл)** Визуализируйте первые десять картинок, расположив их на сетке 3 $\\times$ 4 (в последнем ряду останутся пустые места). Добейтесь, чтобы фон картинок был белым, а изображения цифр – тёмными.\n",
    "\n",
    "*Указания:*\n",
    "- Не забудьте импортировать NumPy и Matplotlib.\n",
    "- Картинки 8 $\\times$ 8 можно либо достать готовыми из объекта, загруженного функцией `load_digits`, либо сделать самостоятельно из строк массива `X`. Во втором случае пользуйтесь методом `reshape`.\n",
    "- Чтобы изображение не было цветным, можно вызвать функцию `plt.gray`, прежде чем начать рисовать.\n",
    "- Располагать картинки на сетке умеет функция `plt.subplot`. Ознакомьтесь со справкой к ней.\n",
    "- По умолчанию число 0 кодирует чёрный цвет, а число 16 – белый цвет. Подумайте, как обратить цвета одной операцией над NumPy-массивом.\n",
    "- Выводить картинку на экран умеет функция `plt.imshow`. Ознакомьтесь со справкой к ней.\n",
    "- Если считаете нужным, можете отключить сглаживание – параметр `interpolation` у функции `plt.imshow`.\n",
    "- Если считаете нужным, можете отключить деления на координатных осях. За это отвечают функции `plt.xticks` и `plt.yticks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, axes = plt.subplots(nrows=2, ncols=5, figsize=(10, 5))\n",
    "for ax, image, label in zip(axes.flatten(), X, y):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape((8, 8)), cmap=plt.cm.gray_r)\n",
    "    ax.set_title(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изменена размерность вывода на 2 на 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Кластеризация и оценка качества\n",
    "\n",
    "Мы будем использовать два популярных алгоритма: иерархическую кластеризацию и метод $K$ средних ($K$-means clustering). Эти и другие алгоритмы кластеризации доступны в библиотеке scikit-learn в подмодуле `cluster`. Иерархическая кластеризация называется `AgglomerativeClustering`, а метод $K$ средних – `KMeans`.\n",
    "\n",
    "Интерфейс у большинства алгоритмов в scikit-learn простой и единообразный:\n",
    "- Чтобы инициализировать модель, нужно создать экземпляр соответствующего класса со всеми необходимыми параметрами. Например, у кластеризаций единственный обязательный параметр называется `n_clusters`, это количество кластеров, которое мы хотим получить на выходе.\n",
    "- Инициализированную модель можно обучить, вызвав метод `fit`.\n",
    "- С помощью обученной модели можно предсказывать, вызывая метод `predict`.\n",
    "\n",
    "Как видно, этот интерфейс хорош только для задач обучения с учителем, в которых чётко разделены фазы обучения модели и предсказания с её помощью. У кластеризаций зато есть метод `fit_predict`, который разбивает входную выборку на кластеры и сразу же возвращает результаты разбиения.\n",
    "\n",
    "**(0.5 балла)** Используя каждый из двух методов, иерархическую кластеризацию и $K$ средних, получите разбиение массива `X` на 10 кластеров.\n",
    "\n",
    "*Указания:*\n",
    "- Оба раза должен получиться массив из 1797 чисел – номеров кластеров.\n",
    "- `KMeans` делает несколько (по умолчанию 10) запусков со случайными центрами и из полученных разбиений выводит лучшее в терминах среднего внутрикластерного расстояния. Чтобы улучшить качество предсказаний, можно увеличить число запусков, например, до 100. Это параметр `n_init` в конструкторе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "\n",
    "My_model= AgglomerativeClustering(n_clusters=10, affinity='euclidean', memory=None, connectivity=None, compute_full_tree='auto', linkage='single', distance_threshold=None, compute_distances=False)\n",
    "clustering = My_model.fit(X)\n",
    "print(clustering.labels_.shape)\n",
    "kmeans_mod = KMeans(n_clusters=10, init='random', n_init=100, max_iter=300, tol=0.0001, precompute_distances='deprecated', verbose=0, random_state=None, copy_x=True, n_jobs='deprecated', algorithm='auto')\n",
    "kmeans=kmeans_mod.fit(X)\n",
    "print(kmeans.labels_.shape)                   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл)** Визуализируйте центры кластеров, полученных каждым из двух способов. Это опять должны быть картинки на сетке 3 $\\times$ 4 с белым фоном и тёмными контурами. Прокомментируйте: какой из двух алгоритмов даёт центры кластеров, больше похожие на типичные начертания цифр?\n",
    "\n",
    "*Указания:*\n",
    "- Центр кластера – это среднее по всем наблюдениям, входящим в кластер, т. е. по какому-то набору строк из `X`.\n",
    "- Чтобы выбрать наблюдения, входящие в кластер номер `i`, используйте индексацию по булевозначной маске. Саму маску можно получить из массива предсказанных номеров кластеров и числа `i` оператором `==`.\n",
    "- Усреднять NumPy-массив вдоль какой-нибудь из осей умеет функция `np.mean`. Ознакомьтесь со справкой к ней. Нам нужно усреднение по строкам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Kmeans\n",
    "i=0\n",
    "mean_X= np.empty((10,64), dtype=\"float\")\n",
    "while i<10:\n",
    "    mean_X[i] = np.mean(X[kmeans.labels_ == i], axis=0)\n",
    "    i+=1\n",
    "_, axes = plt.subplots(nrows=1, ncols=10, figsize=(10, 5))\n",
    "for ax, image in zip(axes.flatten(),mean_X ):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape(8, 8), cmap=plt.cm.gray_r)\n",
    "#AgglomerativeClustering\n",
    "i=0\n",
    "mean_X_2= np.empty((10,64), dtype=\"float\")\n",
    "while i<10:\n",
    "    mean_X_2[i] = np.mean(X[clustering.labels_ == i], axis=0)\n",
    "    i+=1\n",
    "_, axes = plt.subplots(nrows=1, ncols=10, figsize=(10, 5))\n",
    "for ax, image in zip(axes.flatten(),mean_X ):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape(8, 8), cmap=plt.cm.gray_r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ситуации, когда истинное число кластеров неизвестно, подбирают оптимальное число кластеров. При этом учитывают две величины: внутрикластерное расстояние (чем меньше, тем лучше) и межкластерное расстояние (чем больше, тем лучше). Так как две эти величины не достигают оптимума одновременно, обычно оптимизируют какой-нибудь функционал от них. Один популярный функционал называется \"силуэт\" (silhouette). Вот как он вычисляется.\n",
    "\n",
    "Пусть $X$ – множество наблюдений, $M \\subset X$ – один из кластеров, на которые оно разбито в результате кластеризации, $\\rho$ – метрика на $X$. Выберем какое-нибудь одно наблюдение $x \\in M$. Обозначим $a(x)$ среднее расстояние от $x$ до точек $x'$ из того же кластера:\n",
    "$$\n",
    "a(x) = \\frac{1}{|M| - 1} \\sum_{x' \\in M,\\, x' \\ne x} \\rho(x,\\, x')\n",
    "$$\n",
    "\n",
    "Обозначим $b(x)$ минимум средних расстояний от $x$ до точек $x''$ из какого-нибудь другого кластера $N$:\n",
    "$$\n",
    "b(x) = \\min_{N \\ne M} \\frac{1}{|N|} \\sum_{x'' \\in N} \\rho(x,\\, x'')\n",
    "$$\n",
    "\n",
    "Силуэт – это разность межкластерного и внутрикластерного расстояний, нормированная до отрезка $[-1,\\, 1]$ и усреднённая по всем наблюдениям:\n",
    "$$\n",
    "\\frac{1}{|X|} \\sum_{x \\in X} \\frac{b(x) - a(x)}{\\max(a(x),\\, b(x))}\n",
    "$$\n",
    "\n",
    "В scikit-learn силуэт считается функцией `silhouette_score` из подмодуля `metrics`. На вход нужно передать массив наблюдений и результат кластеризации.\n",
    "\n",
    "**(1.5 балла)** Для числа $K$ от 2 до 20 включительно получите разбиение массива `X` на $K$ кластеров каждым из двух методов. Посчитайте силуэт. Посчитанные значения силуэта сохраните в переменную и визуализируйте в виде графика в координатах: число $K$ – значение силуэта. При каком числе кластеров достигается максимум силуэта?\n",
    "\n",
    "*Указания:*\n",
    "- Не забудьте, что функция `range` не захватывает правый конец диапазона.\n",
    "- Под значения силуэта можно завести два списка: один для иерархической кластеризации, другой для $K$ средних.\n",
    "- Рисовать графики умеет функция `plt.plot`. Ознакомьтесь со справкой к ней.\n",
    "- На одной картинке можно разместить несколько графиков, это просто несколько последовательных вызовов `plt.plot`.\n",
    "- Чтобы добавить легенду (подписи к графикам), можно воспользоваться функцией `plt.legend`. Местоположение легенды контролируется параметром `loc`.\n",
    "- Чтобы подписать координатные оси, можно воспользоваться функциями `plt.xlabel` и `plt.ylabel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда известно \"правильное\" (в каком-нибудь смысле) разбиение на кластеры, результат кластеризации можно сравнить с ним, используя такие меры, как однородность (homogeneity), полнота (completeness) и их среднее гармоническое – $V$-мера. Определения этих величин довольно громоздкие и основаны на понятии [энтропии распределения вероятностей](https://ru.wikipedia.org/wiki/Информационная_энтропия); подробности излагаются в [этой статье](http://aclweb.org/anthology/D/D07/D07-1043.pdf). На практике достаточно знать, что однородность, полнота и $V$-мера заключены между нулём и единицей – чем больше, тем лучше.\n",
    "\n",
    "Так как мы знаем, какую цифру на самом деле изображает каждая картинка (это массив `y`), мы можем использовать однородность, полноту и $V$-меру для оценки качества кластеризации. Функции для вычисления этих величин доступны в scikit-learn, в подмодуле `metrics`, под названиями `homogeneity_score`, `completeness_score`, `v_measure_score`. Как вариант, можно использовать функцию `homogeneity_completeness_v_measure`, которая возвращает сразу тройку чисел.\n",
    "\n",
    "**(1 балл)** Повторите предыдущее задание, используя $V$-меру вместо силуэта. При каком числе кластеров достигается максимум $V$-меры?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Снижение размерности признакового пространства\n",
    "\n",
    "Иногда, особенно когда признаков много и не все они одинаково информативные, бывает полезно снизить размерность признакового пространства, то есть вместо $d$ исходных признаков перейти к рассмотрению $d' \\ll d$ новых признаков. Данные были представлены матрицей $n$ наблюдений $\\times$ $d$ исходных признаков, а теперь будут представлены матрицей $n$ наблюдений $\\times$ $d'$ новых признаков.\n",
    "\n",
    "Есть два популярных подхода к снижению размерности:\n",
    "- отобрать (select) новые признаки из числа имеющихся;\n",
    "- извлечь (extract) новые признаки, преобразуя старые, например, сделать $d'$ различных линейных комбинаций столбцов исходной матрицы $n \\times d$.\n",
    "\n",
    "Одним из широко используемых методов извлечения признаков является сингулярное разложение матрицы (singular value decomposition, SVD). Этот метод позволяет сконструировать любое число $d' \\le d$ новых признаков таким образом, что они будут, в определённом смысле, максимально информативными. Математические детали сейчас не важны; познакомиться с ними можно, например, [здесь](https://www.coursera.org/learn/mathematics-and-python/lecture/L9bCV/razlozhieniia-matrits-v-proizviedieniie-singhuliarnoie-razlozhieniie)\n",
    "(по-русски) или [здесь](https://www.youtube.com/watch?v=P5mlg91as1c) (по-английски).\n",
    "\n",
    "В scikit-learn есть несколько реализаций сингулярного разложения. Мы будем использовать класс `TruncatedSVD` из подмодуля `decomposition`. В конструктор этого класса достаточно передать один параметр `n_components` – желаемое число новых признаков. Метод `fit_transform` принимает матрицу и возвращает новую матрицу с таким же количеством строк, как прежде, и количеством столбцов, равным числу новых признаков.\n",
    "\n",
    "<u>Замечание:</u> Сингулярное разложение матрицы $M$ обычно пишут в виде $M = U \\Sigma V^{*}$, где $U$, $\\Sigma$ и $V$ – некие матрицы с хорошими свойствами. То, что возвращает алгоритм `TruncatedSVD`, – это сколько-то (сколько мы хотим получить) первых столбцов матрицы $U$.\n",
    "\n",
    "**(1.5 балла)** Выполните сингулярное разложение матрицы `X`, оставляя 2, 5, 10, 20 признаков. В каждом случае выполните иерархическую и $K$-means кластеризацию преобразованных данных (число кластеров примите равным 10). Посчитайте значения силуэта и $V$-меры. Удалось ли при каком-нибудь $d'$ получить силуэт и / или $V$-меру лучше, чем на исходных данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другая популярная техника снижения размерности, которая особенно хорошо подходит для работы с картинками, – это алгоритм t-distributed stochastic neighbor embeddings, сокращённо tSNE. В отличие от сингулярного разложения, это преобразование нелинейное. Его основная идея – отобразить точки из пространства размерности $d$ в пространство размерности 2 или 3 (обычно 2, то есть на плоскость) таким образом, чтобы как можно точнее сохранить расстояния. Математические детали есть, например, [здесь](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding), но они нетривиальны.\n",
    "\n",
    "В библиотеке scikit-learn реализацией tSNE является класс `TSNE` в подмодуле `manifold`. В конструктор можно передать параметр `n_components`, а можно и не передавать: по умолчанию он равен 2. Метод `fit_transform` работает аналогично тому, как и у `TruncatedSVD`.\n",
    "\n",
    "<u>Замечание:</u> В последние годы вместо tSNE на практике часто используется [UMAP](https://github.com/lmcinnes/umap), более быстрый алгоритм с похожими свойствами. В этой лабораторной работе не предлагается использовать UMAP, так как это потребовало бы установить ещё одну зависимость -- библиотеку `umap-learn`. Желающие могут проделать задания на tSNE с использованием UMAP; в этом случае обратите внимание на параметры `n_neighbors` и `min_dist`, которыми определяется вид проекции.\n",
    "\n",
    "**(0.5 балла)** Выполните tSNE-преобразование матрицы `X`, оставив 2 признака. Визуализируйте данные, преобразованные таким образом, в виде точечной диаграммы: первый признак вдоль горизонтальной оси, второй признак вдоль вертикальной оси. Подсветите разными цветами группы точек, соответствующих разным цифрам.\n",
    "\n",
    "*Указания:*\n",
    "- Точечную диаграмму умеет рисовать функция `plt.scatter`. Ознакомьтесь со справкой к ней.\n",
    "- За цвета точек отвечает параметр `c` у функции `plt.scatter`. Передать в него надо истинные метки классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1 балл)** Для tSNE-преобразованных данных с 2 признаками выполните иерархическую и $K$-means кластеризацию (число кластеров примите равным 10). Посчитайте значения силуэта и $V$-меры. Удалось ли получить силуэт и / или $V$-меру лучше, чем на исходных данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(0.5 балла)** Для самого лучшего разбиения, которое вам удалось получить (на ваше усмотрение, лучшего в терминах силуэта или $V$-меры), опять визуализируйте картинками центры кластеров. Удалось ли добиться, чтобы каждый кластер соответствовал какой-нибудь одной цифре?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Итоги, бонус\n",
    "\n",
    "**(1 балл)** Напишите в свободной форме, какие выводы вы сделали из выполненной работы. Ответьте, как минимум, на следующие два вопроса:\n",
    "- Какой из двух методов даёт более осмысленные кластеры – иерархическая кластеризация или алгоритм $K$ средних? Зависит ли это от настроек каждого алгоритма? От критериев оценивания качества?\n",
    "- Удаётся ли улучшить качество кластеризации, снижая размерность признакового пространства?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(Бонусные 2 балла)** Скачайте датасет [MNIST Handwritten Digits](http://yann.lecun.com/exdb/mnist). Как сделать это с помощью scikit-learn, написано [здесь](http://scikit-learn.org/stable/datasets/index.html#downloading-datasets-from-the-mldata-org-repository). MNIST Handwritten Digits – это 70 тысяч распознанных рукописных изображений цифр, каждое размером 28 $\\times$ 28 пикселей. Попробуйте прокластеризовать этот датасет и добиться как можно лучших значений силуэта и $V$-меры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
